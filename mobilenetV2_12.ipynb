{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"WjCocHugZZQd"},"outputs":[],"source":["## 模型建置\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n","\n","class_num = 12\n","\n","base_model = MobileNetV2(\n","    input_shape=(224,224,3),\n","    include_top=False,\n","    weights=\"imagenet\",\n","    )\n","\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n","\n","inputs = tf.keras.Input(shape=(224,224,3))\n","# 這邊是可以直接添加前處理，讓後續的data_input、prediction不需要前處理\n","x = preprocess_input(inputs)\n","x = base_model(x)#base_model.output # 如果要使用上面的前處理，inputs改成x\n","#在後面接權平均池化\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(128, activation='relu')(x)\n","predictions = Dense(class_num, activation='softmax')(x)\n","\n","model = Model(inputs=inputs, outputs=predictions)\n"]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v4uFcVtJpT1c","executionInfo":{"status":"ok","timestamp":1693272389526,"user_tz":-480,"elapsed":465,"user":{"displayName":"矮黑","userId":"11350692086998618469"}},"outputId":"88e977a4-1c3a-41ec-d8ed-6b9b72d091f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_17 (InputLayer)       [(None, 224, 224, 3)]     0         \n","                                                                 \n"," tf.math.truediv_6 (TFOpLamb  (None, 224, 224, 3)      0         \n"," da)                                                             \n","                                                                 \n"," tf.math.subtract_6 (TFOpLam  (None, 224, 224, 3)      0         \n"," bda)                                                            \n","                                                                 \n"," mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n"," ional)                                                          \n","                                                                 \n"," global_average_pooling2d_9   (None, 1280)             0         \n"," (GlobalAveragePooling2D)                                        \n","                                                                 \n"," dense_16 (Dense)            (None, 128)               163968    \n","                                                                 \n"," dense_17 (Dense)            (None, 12)                1548      \n","                                                                 \n","=================================================================\n","Total params: 2,423,500\n","Trainable params: 2,389,388\n","Non-trainable params: 34,112\n","_________________________________________________________________\n"]}]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1922,"status":"ok","timestamp":1693288381261,"user":{"displayName":"矮黑","userId":"11350692086998618469"},"user_tz":-480},"id":"SvRPPx7Aco-d","outputId":"ff171115-00cc-4169-a260-149898c63c34"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1087 images belonging to 12 classes.\n","Found 248 images belonging to 12 classes.\n","Found 217 images belonging to 12 classes.\n"]}],"source":["from keras.layers.preprocessing.image_preprocessing import Rescaling\n","#讀取資料\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from keras.applications.mobilenet_v2 import preprocess_input\n","TrainDataGenerator = ImageDataGenerator()\n","    # rotation_range=30,  # 随机旋转角度范围为 ±30 度\n","    # width_shift_range=0.2,  # 随机水平平移的范围为 ±20% 的图像宽度\n","    # height_shift_range=0.2,  # 随机垂直平移的范围为 ±20% 的图像高度\n","    # shear_range=0.2,  # 随机剪切的程度为 ±20% 的图像宽度\n","    # zoom_range=0.2,  # 随机缩放范围为 ±20%\n","    # preprocess_input=,)\n","traindata = TrainDataGenerator.flow_from_directory(\n","          directory= \"/content/drive/MyDrive/AI課程/專題/colab_training/select_0827_12/train\",\\\n","          target_size=(224,224),class_mode='categorical',batch_size=32,shuffle=True)\n","\n","valDataGenerator = ImageDataGenerator()\n","valdata = valDataGenerator.flow_from_directory(\n","          directory=\"/content/drive/MyDrive/AI課程/專題/colab_training/select_0827_12/val\", \\\n","          target_size=(224,224),class_mode='categorical',batch_size=32)\n","\n","testDataGenerator = ImageDataGenerator()\n","testdata = testDataGenerator.flow_from_directory(\n","          directory=\"/content/drive/MyDrive/AI課程/專題/colab_training/select_0827_12/test\", \\\n","          target_size=(224,224),class_mode='categorical',batch_size=32)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jZkNQ_5DpuCo"},"outputs":[],"source":["# 編譯模型\n","from tensorflow.keras.optimizers import Adam\n","optimizer = Adam()\n","learning_rate = 0.0002\n","optimizer.lr.assign(learning_rate)\n","model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yl8X5GqPrlsf"},"outputs":[],"source":["# 設定監控方法與條件\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","checkpoint = ModelCheckpoint( filepath=\"/content/drive/MyDrive/AI課程/專題/colab_training/model_save/mobileV2_12.h5\",\n","                monitor='val_accuracy',\n","                verbose=0,\n","                save_best_only=True,\n","                save_weights_only=False,\n","                mode='auto')\n","\n","earlystop = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, verbose=1, mode='auto')"]},{"cell_type":"code","source":["# 模型訓練\n","history = model.fit(traindata, epochs=100, validation_data=valdata, callbacks=[earlystop, checkpoint], verbose = 1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"noZ80eSpyG7b","executionInfo":{"status":"ok","timestamp":1693274182803,"user_tz":-480,"elapsed":1771182,"user":{"displayName":"矮黑","userId":"11350692086998618469"}},"outputId":"ecb3edb1-16f7-4042-dba9-db44fed47be0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","34/34 [==============================] - 119s 3s/step - loss: 0.9329 - accuracy: 0.7452 - val_loss: 0.7779 - val_accuracy: 0.7339\n","Epoch 2/100\n","34/34 [==============================] - 87s 3s/step - loss: 0.0341 - accuracy: 0.9945 - val_loss: 0.4825 - val_accuracy: 0.8226\n","Epoch 3/100\n","34/34 [==============================] - 87s 3s/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.3331 - val_accuracy: 0.9032\n","Epoch 4/100\n","34/34 [==============================] - 88s 3s/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.2963 - val_accuracy: 0.9153\n","Epoch 5/100\n","34/34 [==============================] - 88s 3s/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9234\n","Epoch 6/100\n","34/34 [==============================] - 86s 3s/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.2532 - val_accuracy: 0.9194\n","Epoch 7/100\n","34/34 [==============================] - 87s 3s/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.2202 - val_accuracy: 0.9395\n","Epoch 8/100\n","34/34 [==============================] - 88s 3s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.9435\n","Epoch 9/100\n","34/34 [==============================] - 85s 3s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9435\n","Epoch 10/100\n","34/34 [==============================] - 88s 3s/step - loss: 7.9196e-04 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9476\n","Epoch 11/100\n","34/34 [==============================] - 87s 3s/step - loss: 7.0502e-04 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 0.9516\n","Epoch 12/100\n","34/34 [==============================] - 88s 3s/step - loss: 8.6089e-04 - accuracy: 1.0000 - val_loss: 0.1479 - val_accuracy: 0.9637\n","Epoch 13/100\n","34/34 [==============================] - 86s 3s/step - loss: 6.2599e-04 - accuracy: 1.0000 - val_loss: 0.1452 - val_accuracy: 0.9637\n","Epoch 14/100\n","34/34 [==============================] - 86s 3s/step - loss: 5.5989e-04 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9637\n","Epoch 15/100\n","34/34 [==============================] - 88s 3s/step - loss: 4.0722e-04 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9677\n","Epoch 16/100\n","34/34 [==============================] - 87s 3s/step - loss: 4.2534e-04 - accuracy: 1.0000 - val_loss: 0.1406 - val_accuracy: 0.9637\n","Epoch 17/100\n","34/34 [==============================] - 86s 3s/step - loss: 3.7960e-04 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9637\n","Epoch 18/100\n","34/34 [==============================] - 85s 3s/step - loss: 3.2899e-04 - accuracy: 1.0000 - val_loss: 0.1312 - val_accuracy: 0.9677\n","Epoch 19/100\n","34/34 [==============================] - 86s 3s/step - loss: 3.4841e-04 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9677\n","Epoch 20/100\n","34/34 [==============================] - 87s 3s/step - loss: 3.0146e-04 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9677\n","Epoch 20: early stopping\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-e7rOkhLMEAv"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.plot(history.history[\"accuracy\"])\n","plt.plot(history.history[\"val_accuracy\"])\n","plt.plot(history.history[\"loss\"])\n","plt.plot(history.history[\"val_loss\"])\n","plt.ylabel(\"Accuracy\")\n","plt.xlabel(\"Epoch\")\n","plt.legend([\"acc\",\"val_acc\",\"loss\",\"val_loss\"])\n","plt.show(block=True)"]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","model_load_path = \"/content/drive/MyDrive/AI課程/專題/報告/tf組內報告/mobileV2_12_acc96.h5\"\n","model_save_path = \"/content/drive/MyDrive/AI課程/專題/報告/tf組內報告/thi101_mobileV2\"\n","model = load_model(model_load_path)"],"metadata":{"id":"iYnbNa4R1MgT","executionInfo":{"status":"ok","timestamp":1693288379342,"user_tz":-480,"elapsed":8250,"user":{"displayName":"矮黑","userId":"11350692086998618469"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# 測試集預測\n","evaluation_results = model.evaluate(testdata)\n","print(\"loss:\", evaluation_results[0])\n","print(\"acc:\", evaluation_results[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ajj7nBXV0Qcn","executionInfo":{"status":"ok","timestamp":1693288479655,"user_tz":-480,"elapsed":85537,"user":{"displayName":"矮黑","userId":"11350692086998618469"}},"outputId":"ae9ef167-9d9c-4c1e-c96b-d3a8ccce1ec2"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["7/7 [==============================] - 73s 10s/step - loss: 0.0149 - accuracy: 0.9954\n","loss: 0.014901514165103436\n","acc: 0.9953917264938354\n"]}]},{"cell_type":"code","source":["model.save(model_save_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WcDzb8Lr2oeb","executionInfo":{"status":"ok","timestamp":1693288550737,"user_tz":-480,"elapsed":22493,"user":{"displayName":"矮黑","userId":"11350692086998618469"}},"outputId":"1bd67479-1528-4cfa-f156-3236751eb48d"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QMB1yrMjRgXr"},"outputs":[],"source":["import cv2\n","import matplotlib.pyplot as plt\n","img_path = \"1.JPG\"\n","img = cv2.imread(img_path)\n","plt.figure(figsize=(4, 4))\n","# cv2內建顏色讀取為，BGR，訓練時顏色讀取為RGB，這邊需要做轉換\n","# 有些model在使用Transformer learning時，它們是用BGR做訓練，那就要讓圖片是BGR(EX. VGG16)\n","img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","plt.imshow(img)\n","plt.axis(\"off\")\n","plt.show()"]},{"cell_type":"code","source":["from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n","import numpy as np\n","# 示範沒有前處理的輸出結果\n","img_pre = preprocess_input(img)\n","img_pre"],"metadata":{"id":"qH3pwzN1OeIV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img_pre.shape"],"metadata":{"id":"hW83ry9cMhdG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img_224 = tf.image.resize(img_pre, (224, 224))"],"metadata":{"id":"jikMsykXQE__"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img_224.shape"],"metadata":{"id":"p2gj0B01QwCq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img_224_4 = np.expand_dims(img_224,0)"],"metadata":{"id":"18HHNkl2RAMu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img_224_4.shape"],"metadata":{"id":"NazCgIMdRLbq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred = model.predict(img_224_4)\n","pred"],"metadata":{"id":"hrzj5Y1IPp1E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["index = np.argmax(pred)\n","index"],"metadata":{"id":"lPXkiUVkP5yl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["name_list = [\"GM8\",\"QI8\",\"QY8\",\"TS\"]\n","result = name_list[index]\n","print(\"prediction :\",result)"],"metadata":{"id":"QXecQZNnR4JZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 熱成像，要先觀察整個模型\n","base_model.summary()"],"metadata":{"id":"HUeVLF6LSqMg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"tVB2dPF991yz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 設置一個模型, 此模型會傳回最終卷積層的輸出\n","last_conv_layer_name = \"Conv_1\"  # 最後一層卷積層名稱\n","last_conv_layer = base_model.get_layer(last_conv_layer_name)\n","last_conv_layer_model = tf.keras.Model(base_model.inputs, last_conv_layer.output)"],"metadata":{"id":"eKs0P-UqVjnb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# shape[1:] 主要是移除第 0 軸(批次量軸),這是因為 input()的 shape參數不可以包含批次量\n","classifier_input = tf.keras.Input(shape=last_conv_layer.output.shape[1:])\n","x = classifier_input\n","\n","x = GlobalAveragePooling2D()(x)\n","# x = Dense(2048, activation='relu')(x)\n","x = Dense(128, activation='relu')(x)\n","predictions = Dense(class_num, activation='softmax')(x)\n","\n","classifier_model = tf.keras.Model(classifier_input, x)"],"metadata":{"id":"6Ubtz09XWEpY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","with tf.GradientTape() as tape:\n","    # 將影像傳入至模型運算至最後一層卷積後傳出結果\n","    last_conv_layer_output = last_conv_layer_model(img_224_4)\n","    tape.watch(last_conv_layer_output)\n","    # 取得最高分類類別的激活 channel(下面三行指令)\n","    preds = classifier_model(last_conv_layer_output)\n","    # 取得最高分類別的梯度\n","    top_pred_index = tf.argmax(preds[0])\n","    top_class_channel = preds[:, top_pred_index]\n","#　計算＂最高分的預測類別＂相對於＂最終卷積之輸出特徵圖＂的梯度\n","grads = tape.gradient(top_class_channel, last_conv_layer_output)"],"metadata":{"id":"9OXSC0kxXCqY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 梯度池化及channel重要性加權\n","# 會計算出一個向量，它的每個元素都是特定channel的平均梯度(它量化了每個channel對最高分類別的重要程度)\n","# 會陸續沿著第0,1,2軸做平均,因此這三軸會消失,最後只剩下第3軸(channel)\n","pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2)).numpy()\n","last_conv_layer_output = last_conv_layer_output.numpy()[0]\n","for i in range(pooled_grads.shape[-1]):\n","    last_conv_layer_output[:, :, i] *= pooled_grads[i]\n","heatmap = np.mean(last_conv_layer_output, axis=-1)"],"metadata":{"id":"QjdIX4w1XKu-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 將熱力圖正規化\n","import matplotlib.pyplot as plt\n","heatmap = np.maximum(heatmap, 0)\n","heatmap /= np.max(heatmap)\n","plt.matshow(heatmap)"],"metadata":{"id":"BsBchSARXMJZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 疊加熱力圖和原始影像\n","import matplotlib as mpl\n","# 載入原始影像\n","img = tf.keras.utils.load_img(img_path)\n","img = tf.keras.utils.img_to_array(img)\n","# 將熱力圖中的數值調整到 0-255 之間\n","heatmap = np.uint8(255 * heatmap)\n","# 使用 jet 色盤對熱力圖著色(以下三行)\n","jet = mpl.colormaps.get_cmap(\"jet\")\n","jet_colors = jet(np.arange(256))[:, :3]\n","jet_heatmap = jet_colors[heatmap]\n","# 創建一個包含重新著色之熱力圖的影像(以下三行)\n","jet_heatmap = tf.keras.utils.array_to_img(jet_heatmap)\n","jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n","jet_heatmap = tf.keras.utils.img_to_array(jet_heatmap)\n","# 疊加熱力圖與原圖, 熱力圖的不透明度為 40%\n","superimposed_img = jet_heatmap * 0.4 + img\n","superimposed_img = tf.keras.utils.array_to_img(superimposed_img)\n","rotated_superimposed_img = superimposed_img.rotate(-90)\n","\n","save_path = \"combine.jpg\"\n","rotated_superimposed_img.save(save_path) # 儲存疊加後的影像"],"metadata":{"id":"nGkxRFphXrlh"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.17"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}